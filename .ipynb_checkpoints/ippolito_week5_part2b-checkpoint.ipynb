{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e381eb91-5108-47fa-b9e1-5ca559a7a0ce",
   "metadata": {},
   "source": [
    "### DATA620 - Week5, Part 2\n",
    "#### Michael Ippolito\n",
    "6/30/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1602eb0-e8cb-42cf-8b36-ac80129cf66b",
   "metadata": {
    "tags": []
   },
   "source": [
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data:  UCI Machine Learning Repository: Spambase Data Set\n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.\n",
    "\n",
    "This assignment is due end of day on Sunday.\n",
    "\n",
    "NOTE: This is a two week assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0933dc-dbc0-435c-9fb0-c8bb4880801a",
   "metadata": {},
   "source": [
    "### Oveview\n",
    "\n",
    "For this assignment, I used a set of documents downloaded from https://github.com/t-davidson/hate-speech-and-offensive-language. The documents are labeled as either containing hate speech, offensive language, or neither. I built a Naive Bayes model to classify the documents, paritioning the set into training and test folds, then assessed the model to evaluate its performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64096232-12f9-4ed6-b2a2-43fada962ffc",
   "metadata": {},
   "source": [
    "### Link to video presentation\n",
    "\n",
    "[Video](https://github.com/mmippolito/cuny_data620_week5_part2/blob/main/ippolito_video.mp4?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e00e0c1-0fea-4cce-9a68-0af39756d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features\n",
    "from nltk.metrics import ConfusionMatrix, precision, recall\n",
    "import nltk\n",
    "import random\n",
    "import math\n",
    "import collections\n",
    "\n",
    "# Set module options\n",
    "pio.renderers.default = 'jupyterlab'    # Set ploty renderer so graphs show up in HTML output\n",
    "pd.set_option('display.width', 160)    # Set pandas display options\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58603737-dca9-4071-a600-46c069bc4c31",
   "metadata": {},
   "source": [
    "### Fetch Data\n",
    "\n",
    "First, fetch the data from github if it already isn't on the local drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09912b09-84a9-4054-a143-c34b591af385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV already exists on disk\n"
     ]
    }
   ],
   "source": [
    "# Fetch data from github; source: https://github.com/t-davidson/hate-speech-and-offensive-language\n",
    "\n",
    "# Fetch data from github repo and store in current directory\n",
    "def fetch_data(fn, url):\n",
    "    if not os.path.exists('hate_speech_labeled_data.csv'):\n",
    "        print('Downloading', fn)\n",
    "        try:\n",
    "            r = requests.get(url).text\n",
    "            fh = open(fn, 'w', encoding='utf-8')\n",
    "            fh.write(r)\n",
    "            fh.close()\n",
    "        except:\n",
    "            return 1\n",
    "    else:\n",
    "        print('CSV already exists on disk')\n",
    "    return 0\n",
    "\n",
    "# Fetch data\n",
    "fn = 'hate_speech_labeled_data.csv'\n",
    "url = 'https://github.com/t-davidson/hate-speech-and-offensive-language/blob/master/data/labeled_data.csv?raw=true'\n",
    "err = fetch_data(fn, url)\n",
    "if err > 0:\n",
    "    assert(False, 'An error occured trying to download or save the csv.')\n",
    "\n",
    "# Load csv into pandas dataframe\n",
    "df1 = pd.read_csv(fn)\n",
    "\n",
    "# Convert labels to text\n",
    "df1.loc[df1['class'] == 0, 'label'] = 'hate_speech'\n",
    "df1.loc[df1['class'] == 1, 'label'] = 'offensive_language'\n",
    "df1.loc[df1['class'] == 2, 'label'] = 'neither'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d38b3-97b0-49f6-9d48-6f68722895b7",
   "metadata": {},
   "source": [
    "Readme from github repo (https://github.com/t-davidson/hate-speech-and-offensive-language):\n",
    "\n",
    "The data are stored as a CSV and as a pickled pandas dataframe (Python 2.7). Each data file contains 5 columns:\n",
    "* count = number of CrowdFlower users who coded each tweet (min is 3, sometimes more users coded a tweet when judgments were determined to be unreliable by CF).\n",
    "* hate_speech = number of CF users who judged the tweet to be hate speech.\n",
    "* offensive_language = number of CF users who judged the tweet to be offensive.\n",
    "* neither = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
    "* class = class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef121fc-3b28-4810-a15a-a744b6d1391c",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "Perform exploratory data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f70ad5e-df1d-44f6-b030-569c6f9b2976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          24783 non-null  int64 \n",
      " 1   count               24783 non-null  int64 \n",
      " 2   hate_speech         24783 non-null  int64 \n",
      " 3   offensive_language  24783 non-null  int64 \n",
      " 4   neither             24783 non-null  int64 \n",
      " 5   class               24783 non-null  int64 \n",
      " 6   tweet               24783 non-null  object\n",
      " 7   label               24783 non-null  object\n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 1.5+ MB\n",
      "None\n",
      "\n",
      "Summary stats:\n",
      "         Unnamed: 0         count   hate_speech  offensive_language       neither         class\n",
      "count  24783.000000  24783.000000  24783.000000        24783.000000  24783.000000  24783.000000\n",
      "mean   12681.192027      3.243473      0.280515            2.413711      0.549247      1.110277\n",
      "std     7299.553863      0.883060      0.631851            1.399459      1.113299      0.462089\n",
      "min        0.000000      3.000000      0.000000            0.000000      0.000000      0.000000\n",
      "25%     6372.500000      3.000000      0.000000            2.000000      0.000000      1.000000\n",
      "50%    12703.000000      3.000000      0.000000            3.000000      0.000000      1.000000\n",
      "75%    18995.500000      3.000000      0.000000            3.000000      0.000000      1.000000\n",
      "max    25296.000000      9.000000      7.000000            9.000000      9.000000      2.000000\n",
      "\n",
      "First few observations:\n",
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class                                              tweet               label\n",
      "0           0      3            0                   0        3      2  !!! RT @mayasolovely: As a woman you shouldn't...             neither\n",
      "1           1      3            0                   3        0      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  offensive_language\n",
      "2           2      3            0                   3        0      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  offensive_language\n",
      "3           3      3            0                   2        1      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  offensive_language\n",
      "4           4      6            0                   6        0      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  offensive_language\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EDA\n",
    "\n",
    "# Display info about the data\n",
    "print('Column info:')\n",
    "print(df1.info())\n",
    "print()\n",
    "print('Summary stats:')\n",
    "print(df1.describe())\n",
    "print()\n",
    "print('First few observations:')\n",
    "print(df1.head())\n",
    "\n",
    "# Bar chart of labeled classes\n",
    "dfgrp = df1.groupby(['label'], as_index=False).count()\n",
    "print()\n",
    "plt.bar(x=dfgrp['label'], height=dfgrp['count'])\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of labeled classes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb90981-534b-402c-926c-10cccf5484ca",
   "metadata": {},
   "source": [
    "As illustrated by the bar chart, the data is unbalanced heavily in favour of offensive language. This indicates that accuracy will most likely not be the best measure of model performance, and/or that either oversampling or understampling might be in order. In this case, we don't want to lose any data, so we'll reject undersampling of the majority class. And to avoid overfitting, we'll also reject oversampling the minority classes. Instead, we'll use alternate metrics (precision, recall, F1-score).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc01c2-d7a3-4861-b9de-9ef9a013ffff",
   "metadata": {},
   "source": [
    "### Create Corpus\n",
    "\n",
    "Create a corpus, i.e. an array of documents, which will be a list of tuples containing the text of the tweet and the corresponding label for that text. Then we'll tokenize the corpus using a naive approach, i.e. a simple word tokenizer using NLTK's built-in word_tokenize function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f7f467-257d-4ae3-b31f-88bdb69deb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few documents:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[.@AussieGrit, loves, Austin:, http://t.co/HTt...</td>\n",
       "      <td>neither</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[I'm, about, to, push, this, niggah, off, my, ...</td>\n",
       "      <td>offensive_language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[@_BeverlyNoHills, you, so, fucking, nasty., Y...</td>\n",
       "      <td>offensive_language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[That's, Ya, BM, tho, RT, @Tyga:, That, ain't,...</td>\n",
       "      <td>offensive_language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Bad, bitches, and, good, weed]</td>\n",
       "      <td>offensive_language</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                   1\n",
       "0  [.@AussieGrit, loves, Austin:, http://t.co/HTt...             neither\n",
       "1  [I'm, about, to, push, this, niggah, off, my, ...  offensive_language\n",
       "2  [@_BeverlyNoHills, you, so, fucking, nasty., Y...  offensive_language\n",
       "3  [That's, Ya, BM, tho, RT, @Tyga:, That, ain't,...  offensive_language\n",
       "4                    [Bad, bitches, and, good, weed]  offensive_language"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create document array, which will be a list of tuples (text, label)\n",
    "labels = list(df1['label'])\n",
    "texts = list(df1['tweet'])\n",
    "documents = []\n",
    "for i, text in enumerate(texts):\n",
    "    documents.append((text.split(), labels[i]))\n",
    "random.shuffle(documents)\n",
    "print('First few documents:')\n",
    "display(pd.DataFrame(documents[:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f5a27dc-81ab-49e4-b8e1-18c500475b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize; we'll use a naive approach and use a simple tokenizer.\n",
    "# This takes a while, so keep it within its own code block.\n",
    "tokens = nltk.word_tokenize(' '.join(texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83718fa2-26c3-4b55-9aff-b26261443a4a",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "\n",
    "Next, we'll extract the features from each document. For the feature set, we'll use the top 2,000 most frequently used words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c637fc1-0a13-436c-ae5b-98aec8d0b658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a list of the most frequent 2000 words\n",
    "all_words = nltk.FreqDist(w.lower() for w in tokens)\n",
    "word_features = list(all_words)[:2000]\n",
    "\n",
    "# Create list of top 20 most frequent words; reverse it for the bar graph\n",
    "x = [word for word in list(word_features)[:20]]\n",
    "y = [all_words.freq(word) for word in x]\n",
    "x.reverse()\n",
    "y.reverse()\n",
    "\n",
    "# Bar graph\n",
    "plt.barh(width=y, y=x)\n",
    "plt.xlabel('Relative frequency')\n",
    "plt.ylabel('Word')\n",
    "plt.title('Relative frequencies of top 20 most frequent words')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "821f745e-d640-4fe8-8540-67e89bb81b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to generate document features\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "143e701f-f511-43f5-999c-d493bbf3fe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create featuresets for each document\n",
    "featuresets = [(document_features(d), c) for (d, c) in documents]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f56e8f9-9550-415e-bf3c-0ef17ea18329",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "\n",
    "Partition the data into 70% training data, 30% test data. Then train the model using a naive Bayes classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e6d2fc3-fc37-46ae-9240-193592757c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training docs: 17348\n",
      "Test docs: 7435\n"
     ]
    }
   ],
   "source": [
    "# Partition data into training and test sets\n",
    "train_pct = 0.7\n",
    "train_doc_ct = int(len(documents) * train_pct)\n",
    "train_set, test_set = featuresets[train_doc_ct:], featuresets[:train_doc_ct]\n",
    "print('Training docs:', train_doc_ct)\n",
    "print('Test docs:', len(documents) - train_doc_ct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d27a7822-05bb-4ee8-9ac4-8a7c1edf7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91d2b97b-018d-4057-a43d-9ad7a32a8056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8381369610329721\n",
      "Most Informative Features\n",
      "         contains(bitch) = True           offens : neithe =     74.1 : 1.0\n",
      "         contains(pussy) = True           offens : neithe =     64.1 : 1.0\n",
      "          contains(shit) = True           offens : neithe =     40.0 : 1.0\n",
      "      contains(brownies) = True           neithe : offens =     38.6 : 1.0\n",
      "          contains(hoes) = True           offens : neithe =     33.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print out accuracy for reference, even though we'll use a different set of metrics to actually evaluate the model\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "classifier.show_most_informative_features(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25598176-d1e8-44de-8400-85df15b2464a",
   "metadata": {},
   "source": [
    "### Evaluate Test Set\n",
    "\n",
    "Evaluate the test set by comparing reference labels against predicted labels. Precision, recall, and F1 scores were calculated for each label. A confusion matrix had to be generated manually because of an error in the NLTK ConfusionMatrix function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74890307-8005-411f-9027-885a8711a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data\n",
    "\n",
    "# Create empty reference and test sets\n",
    "refsets = {}\n",
    "testsets = {}\n",
    "for label in list(dfgrp['label']):\n",
    "    refsets[label] = set()\n",
    "    testsets[label] = set()\n",
    "\n",
    "# Populate reference and test sets with reference and predicted labels\n",
    "for i, (feats, label) in enumerate(test_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fa78e68-2011-47ad-969b-53f7636df9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate_speech:\n",
      "\tprecision=0.3230088495575221\n",
      "\trecall=0.14762386248736098\n",
      "\tf1-score=0.20263705759888967\n",
      "neither:\n",
      "\tprecision=0.7207425343018563\n",
      "\trecall=0.6078965282505105\n",
      "\tf1-score=0.6595273264401773\n",
      "offensive_language:\n",
      "\tprecision=0.8744624774587322\n",
      "\trecall=0.9394232918560464\n",
      "\tf1-score=0.9057796616257768\n",
      "\n",
      "Confusion matrix:\n",
      "Actual values in rows ['hate_speech', 'neither', 'offensive_language']\n",
      "Predicted values in columns ['hate_speech', 'neither', 'offensive_language']\n",
      "[[  146   126   717]\n",
      " [   59  1786  1093]\n",
      " [  247   566 12608]]\n",
      "\n",
      "Geometric mean of F! scores: 0.49468044560670515\n"
     ]
    }
   ],
   "source": [
    "# model metrics\n",
    "\n",
    "# Show precision and recall\n",
    "f1_scores = []\n",
    "for label in list(dfgrp['label']):\n",
    "    print(label + ':')\n",
    "    p1 = precision(refsets[label], testsets[label])\n",
    "    r1 = recall(refsets[label], testsets[label])\n",
    "    f1 = 2 / ((1/p1) + (1/r1))\n",
    "    f1_scores.append(f1)\n",
    "    print('\\tprecision=' + str(p1))\n",
    "    print('\\trecall=' + str(r1))\n",
    "    print('\\tf1-score=' + str(f1))\n",
    "print()\n",
    "\n",
    "# Generate confusion matrix (the nltk ConfusionMatrix function generated an error, so I had to do this manually)\n",
    "row = []\n",
    "for label1 in refsets:\n",
    "    col = []\n",
    "    for label2 in testsets:\n",
    "        ct = len(list(set(refsets[label1]) & set(testsets[label2])))    # find intersection of the two sets\n",
    "        col.append(ct)\n",
    "    row.append(col)\n",
    "cm = np.matrix(row)\n",
    "print('Confusion matrix:')\n",
    "print('Actual values in rows ' + str([label for label in list(dfgrp['label'])]))\n",
    "print('Predicted values in columns ' + str([label for label in list(dfgrp['label'])]))\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# Find geometric mean of F1 scores\n",
    "ttl = 1\n",
    "for f1 in f1_scores:\n",
    "    ttl *= f1\n",
    "f1_geom_mean = ttl ** (1 / len(f1_scores))\n",
    "print('Geometric mean of F1 scores:', f1_geom_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110f615-e86a-48e8-8293-f4844fb6099f",
   "metadata": {},
   "source": [
    "### Analysis and Conclusions\n",
    "\n",
    "Based on the results, the model performed rather poorly at classifying hate speech, with only an F1 score of 0.203. Documents labeled \"neither\" fared a little better, with an F1 score of 0.660. The model performed the best at classifying offensive language, with an F1 score of 0.906. Overall, the geometric mean of the F1 scores was 0.495, indicating a relatively poor fit.\n",
    "\n",
    "I made further attempts to improve the score by trying to oversample the minority classes, but the model performed slighly worse. The best improvement seemed to arise from increasing the number of features used; I tried 500, then 1000, 2000, which produced incrementally higher F1 scores. I also attempted to snip off the top several hundred terms, thinking that these terms would appear across all document categories. I also tried tokenizing by not only unigrams but by bigrams. But none outperformed the simpler model that blindly used the top most frequently used unigrams.\n",
    "\n",
    "This indicates that there is enough ambiguity in what might be considered hate speech that it would be difficult for ML to discern it without further investigation. Because these samples were classified rather arbitrarily by end users rather than against a more rigid, codified standard, it isn't surprising that any attempt to model the data would yield tepid results.\n",
    "\n",
    "From the confusion matrix, we see in the first row that the model often misclassifed hate speech as offensive language. Similarly, language that is neither hate speech nor offensive language was misclassified, further confirming that there is a lot of ambiguity around what constitues either of these types of language.\n",
    "\n",
    "Further investigation might include removing stopwords, punctuation, or other markers that might be reducing the model's performance. Network analysis of the users who composed the tweets could also yield more accurate results, based on who the users' connections are.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
